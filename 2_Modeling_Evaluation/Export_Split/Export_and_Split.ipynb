{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Random_Split.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Installing libraries"
   ],
   "metadata": {
    "id": "jF3nuFRv6dXA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oa23ezWidgu",
    "outputId": "9d5e6533-9daf-4fa5-877a-fe797cd27d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: segments-ai in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (0.54)\n",
      "Requirement already satisfied: requests in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from segments-ai) (2.25.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from segments-ai) (0.19.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from segments-ai) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from segments-ai) (1.20.1)\n",
      "Requirement already satisfied: pycocotools-windows in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from segments-ai) (2.0.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from segments-ai) (4.62.3)\n",
      "Requirement already satisfied: setuptools>=18.0 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from pycocotools-windows->segments-ai) (52.0.0.post20210125)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from pycocotools-windows->segments-ai) (3.3.1)\n",
      "Requirement already satisfied: cython>=0.27.3 in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from pycocotools-windows->segments-ai) (0.29.26)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows->segments-ai) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows->segments-ai) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows->segments-ai) (2020.12.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows->segments-ai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools-windows->segments-ai) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools-windows->segments-ai) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->segments-ai) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->segments-ai) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests->segments-ai) (2.10)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->segments-ai) (2021.11.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from scikit-image->segments-ai) (1.6.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->segments-ai) (2.13.5)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from scikit-image->segments-ai) (2.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->segments-ai) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from scikit-image->segments-ai) (20.9)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from networkx>=2.2->scikit-image->segments-ai) (4.4.2)\n",
      "Requirement already satisfied: colorama in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from tqdm->segments-ai) (0.4.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: boltons in c:\\users\\thomas\\appdata\\roaming\\python\\python37\\site-packages (21.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install segments-ai\n",
    "!pip install boltons"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "Zqs0MU9kifpg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from segments import SegmentsClient, SegmentsDataset\n",
    "from segments.utils import export_dataset\n",
    "import os\n",
    "import shutil\n",
    "import pytz\n",
    "import datetime\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "import pycocotools.mask as mask\n",
    "import cv2\n",
    "from boltons.iterutils import remap"
   ],
   "metadata": {
    "id": "CRUzNe9qiemq"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Methods"
   ],
   "metadata": {
    "id": "pIKcUtF2ijZk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"Loading release file as dictionary, rename filename, filter and resave\"\"\"\n",
    "def cleanup_json(directory, filename):\n",
    "    release=os.path.join(directory, filename)\n",
    "    f = open(release)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    for item in data[\"dataset\"][\"samples\"]: #Rename filename in json (error in Amazon S3 bucket)\n",
    "      item[\"name\"] = item[\"name\"].replace('all/', '')\n",
    "    data = [d for d in data[\"dataset\"][\"samples\"] if d[\"labels\"][\"ground-truth\"] != None] # filter unlabeled images\n",
    "    data = [d for d in data if d[\"labels\"][\"ground-truth\"][\"label_status\"] != \"SKIPPED\"] # filter skipped images\n",
    "    data = [d for d in data if d[\"labels\"][\"ground-truth\"][\"attributes\"][\"annotations\"] != []] # filter images without annotations (pv nor thermal)\n",
    "    with open(os.path.join(directory, \"solar_panels_filt.json\"),'w') as f: #save as *_filt.json\n",
    "      json.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "\"\"\"Loading release file as dictionary, rename filename, light filter and resave for exploratory data analysis\"\"\"\n",
    "def cleanup_json_eda(directory, filename):\n",
    "    release=os.path.join(directory, filename)\n",
    "    f = open(release)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    for item in data[\"dataset\"][\"samples\"]: #Rename filename in json (error in Amazon S3 bucket)\n",
    "      item[\"name\"] = item[\"name\"].replace('all/', '')\n",
    "    data = [d for d in data[\"dataset\"][\"samples\"] if d[\"labels\"][\"ground-truth\"] != None] # filter unlabeled images\n",
    "    data = [d for d in data if d[\"labels\"][\"ground-truth\"][\"label_status\"] != \"SKIPPED\"] # filter skipped images\n",
    "    with open(os.path.join(directory, \"solar_panels_eda.json\"),'w') as f: #save as *_filt.json\n",
    "      json.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def polygonFromMask(maskedArr):\n",
    "  # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py\n",
    "  contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  segmentation = []\n",
    "  valid_poly = 0\n",
    "  for contour in contours:\n",
    "  # Valid polygons have >= 6 coordinates (3 points)\n",
    "     if contour.size >= 6:\n",
    "        segmentation.append(contour.astype(float).flatten().tolist())\n",
    "        valid_poly += 1\n",
    "  if valid_poly == 0:\n",
    "     raise ValueError\n",
    "  return segmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def cleanup(directory, filename):\n",
    "    path=os.path.join(directory, filename)\n",
    "    json_file = open(path)\n",
    "    coco_json = json.load(json_file)\n",
    "    json_file.close()\n",
    "    for i in coco_json[\"categories\"]: # change 0 to 1 (pv), change 1 to 2 (thermal) => 0 belongs to background class\n",
    "        if i[\"id\"] == 1:\n",
    "            i[\"id\"] = 2\n",
    "        elif i[\"id\"] == 0:\n",
    "            i[\"id\"] = 1\n",
    "    for j in coco_json[\"annotations\"]: # change 0 to 1 (pv), change 1 to 2 (thermal) => 0 belongs to background class\n",
    "        if j[\"category_id\"] == 1:\n",
    "            j[\"category_id\"] = 2\n",
    "        elif j[\"category_id\"] == 0:\n",
    "            j[\"category_id\"] = 1\n",
    "    for l in coco_json[\"images\"]: # change png to tif\n",
    "        l[\"file_name\"] = l[\"file_name\"].replace(\".png\", \".tif\")\n",
    "    bad_keys = {'size'}  #delete size\n",
    "    for m in coco_json[\"annotations\"]: # decode mask\n",
    "        maskedArr = mask.decode(m[\"segmentation\"])\n",
    "        m[\"segmentation\"][\"counts\"] = polygonFromMask(maskedArr)\n",
    "        area = float((maskedArr > 0.0).sum())\n",
    "        m[\"area\"] = area\n",
    "    drop_keys = lambda paths, key, value: key not in bad_keys\n",
    "    coco_json = remap(coco_json, visit=drop_keys)\n",
    "    with open(filename, \"w\") as fp:\n",
    "        json.dump(coco_json, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def log(msg='...', path=''):\n",
    "    tz_ZH = pytz.timezone('Europe/Zurich') \n",
    "    now = datetime.datetime.now(tz_ZH)\n",
    "    now_string = now.strftime(\"%H:%M:%S\")\n",
    "    print('log: {} {:<20s} {:>45}'.format(now_string, msg, path))"
   ],
   "metadata": {
    "id": "o70y1n75inJy"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def download_file_from_google_drive(id, destination):\n",
    "    # source https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url/60132855#60132855\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "             for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination) "
   ],
   "metadata": {
    "id": "Z-i3MWGYipnQ"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "parent_dir='data'\n",
    "if not os.path.exists(parent_dir):    \n",
    "    log('creating directory:',parent_dir)\n",
    "    os.makedirs(parent_dir)\n",
    "    \n",
    "directories=['01_downloads']\n",
    "for dir in directories: \n",
    "    path = os.path.join(parent_dir, dir) \n",
    "    if not os.path.exists(path):    \n",
    "        os.makedirs(path) \n",
    "        log('creating directory:',path)"
   ],
   "metadata": {
    "id": "pxWjOYrmirC4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4fe89c02-6fb6-4669-fc6b-f1585e35d58c"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Downloading released labeling data from Google Drive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: 11:44:04 downloading:         data\\01_downloads\\solar_panels-v0.5_copy.json\n"
     ]
    }
   ],
   "source": [
    "downloading = {\"solar_panels-v0.5_copy\": \"15cuEnval79LIX0K9wadmbG-yevGjNgKu\"} # file name : file id\n",
    "download_dir = os.path.join(parent_dir, directories[0]) # path to directory \"01_downloads\"\n",
    "\n",
    "for file_name, file_id in downloading.items():\n",
    "  path=os.path.join(download_dir, file_name+\".json\")\n",
    "  log(\"downloading:\", path)\n",
    "  download_file_from_google_drive(file_id, path) # download and save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cleanup JSON"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "path = \"C:/Users/Thomas/PycharmProjects/pythonProject/data/01_downloads/\"  # path to loaded json\n",
    "file = \"solar_panels-v0.5_copy.json\" #json filename\n",
    "cleanup_json(path, file) #make improvements for further preparations, save \"solar_panels_filt.json\"\n",
    "#cleanup_json_eda(path, file) #make improvements for exploratory data analysis, save \"solar_panels_eda.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "=> Unfortunately manual work:\n",
    "+ Adding filtered keys again according \"solar_panels-v0.5_copy.json\"\n",
    "+ resave json in same destination path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reopen *_filt.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized successfully.\n",
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2179/2179 [00:03<00:00, 569.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 2179 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a SegmentsDataset from the release file\n",
    "client = SegmentsClient(api_key='0e37cf5cca4fe748d5277b9893d3a95a08f2bd31')\n",
    "release = \"C:/Users/Thomas/PycharmProjects/pythonProject/data/01_downloads/solar_panels_filt.json\" # eventually adjusting path\n",
    "dataset = SegmentsDataset(release, labelset='ground-truth', filter_by=['labeled'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Splitting<h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating list of names of labeled images"
   ],
   "metadata": {
    "id": "4Nfp9JlIi3ZU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "imageNames = []\n",
    "for sample in dataset:\n",
    "  imageNames.append(sample[\"name\"])"
   ],
   "metadata": {
    "id": "nHkXYPbBi7WP"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shuffling name list"
   ],
   "metadata": {
    "id": "ZpHxxewFaEAN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "imageNames.sort() # make sure that the filenames have a fixed order before shuffling\n",
    "random.seed(230) # make it reproducible\n",
    "random.shuffle(imageNames) # shuffles the ordering of filenames (deterministic given the chosen seed)"
   ],
   "metadata": {
    "id": "WzREYGIBaG1d"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting into train, validation, test set"
   ],
   "metadata": {
    "id": "g2d0ZJ_vaI8Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "split_1 = int(0.5 * len(imageNames)) # 50 %\n",
    "split_2 = int(0.75 * len(imageNames)) # 25 % each\n",
    "train_filenames = imageNames[:split_1]\n",
    "val_filenames = imageNames[split_1:split_2]\n",
    "test_filenames = imageNames[split_2:]"
   ],
   "metadata": {
    "id": "lFQLb8mCXTLt"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change format name \".png\" to \".tif\""
   ],
   "metadata": {
    "id": "eWpKLyjzDaPI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_filenames_tif = [item.replace(\".png\", \".tif\") for item in train_filenames]\n",
    "val_filenames_tif = [item.replace(\".png\", \".tif\") for item in val_filenames]\n",
    "test_filenames_tif = [item.replace(\".png\", \".tif\") for item in test_filenames]"
   ],
   "metadata": {
    "id": "VrCd1pXsDVrO"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Copying labeled images (.tif) according to list to a new folder (.tif)"
   ],
   "metadata": {
    "id": "brIrF9IQD3rj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "src_dir = \"D:/Model/all_labeled_uint8_hm\" # path to current files\n",
    "dst_dir = \"D:/Model/2_Histogram-Matching2/train/\" # new file path\n",
    "for imageName in train_filenames_tif:\n",
    "    shutil.copy(os.path.join(src_dir, imageName), dst_dir)"
   ],
   "metadata": {
    "id": "ev-tq4lsvtYG"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "src_dir = \"D:/Model/all_labeled_uint8_hm\" # path to current files\n",
    "dst_dir = \"D:/Model/2_Histogram-Matching2/val/\" # new file path\n",
    "for imageName in val_filenames_tif:\n",
    "    shutil.copy(os.path.join(src_dir, imageName), dst_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "src_dir = \"D:/Model/all_labeled_uint8_hm\" # path to current files\n",
    "dst_dir = \"D:/Model/2_Histogram-Matching2/test/\" # new file path\n",
    "for imageName in test_filenames_tif:\n",
    "    shutil.copy(os.path.join(src_dir, imageName), dst_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing dictionary with each set"
   ],
   "metadata": {
    "id": "s-RUbYmSlyY1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "f = open(release, \"r\")\n",
    "data = json.loads(f.read())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train = [d for d in data[\"dataset\"][\"samples\"] if d[\"name\"] in train_filenames]\n",
    "validation = [d for d in data[\"dataset\"][\"samples\"] if d[\"name\"] in val_filenames]\n",
    "test = [d for d in data[\"dataset\"][\"samples\"] if d[\"name\"] in test_filenames]"
   ],
   "metadata": {
    "id": "fkAIw-gsTdeM"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "resave json file"
   ],
   "metadata": {
    "id": "eBlW6tkzmtyk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"train.json\", \"w\") as fp:\n",
    "  json.dump(train, fp)"
   ],
   "metadata": {
    "id": "j7_gDlOGZSbY"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"val.json\", \"w\") as fp:\n",
    "  json.dump(validation, fp)"
   ],
   "metadata": {
    "id": "fqyDmyS5sncy"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"test.json\", \"w\") as fp:\n",
    "  json.dump(test, fp)"
   ],
   "metadata": {
    "id": "MmuVB5_ftD_9"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "=> Unfortunately manual work:\n",
    "+ Adding filtered keys again according \"solar_panels-v0.5_filt.json\"\n",
    "+ resave json"
   ],
   "metadata": {
    "id": "oVjAefB-BPkf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Exporting labels to COCO instance segmentation format and save as *.json<h4>"
   ],
   "metadata": {
    "id": "RL1dHgrENA1l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_train = SegmentsDataset(\"C:/Users/Thomas/PycharmProjects/pythonProject/data/01_downloads/solar_panels_filt.json\", labelset='ground-truth', filter_by=['labeled'])\n",
    "export_dataset(dataset_train, export_format='coco-instance')"
   ],
   "metadata": {
    "id": "9g-LY_Cwi890",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e0385296-6502-4f12-9bf1-35bd8a737b39"
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2179/2179 [00:03<00:00, 673.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 2179 images.\n",
      "Exporting dataset. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2179/2179 [00:30<00:00, 70.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to .\\export_coco-instance_charlie4611-_solar_panels_v0.5.4.json. Images and labels in segments\\charlie4611-_solar_panels\\v0.5.4\n"
     ]
    },
    {
     "data": {
      "text/plain": "('.\\\\export_coco-instance_charlie4611-_solar_panels_v0.5.4.json',\n 'segments\\\\charlie4611-_solar_panels\\\\v0.5.4')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_validation = SegmentsDataset(\"C:/Users/Thomas/PycharmProjects/pythonProject/val.json\", labelset='ground-truth', filter_by=['labeled'])\n",
    "export_dataset(dataset_validation, export_format='coco-instance')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4yIAKuIrI6Sq",
    "outputId": "c412ecdc-ad66-4939-b663-c5834dfdfa5c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 545/545 [00:00<00:00, 1054.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 545 images.\n",
      "Exporting dataset. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 545/545 [00:07<00:00, 73.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to .\\export_coco-instance_charlie4611-_solar_panels_v0.5.4.json. Images and labels in segments\\charlie4611-_solar_panels\\v0.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "('.\\\\export_coco-instance_charlie4611-_solar_panels_v0.5.4.json',\n 'segments\\\\charlie4611-_solar_panels\\\\v0.5.4')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 545/545 [00:00<00:00, 1023.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 545 images.\n",
      "Exporting dataset. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 545/545 [00:07<00:00, 71.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to .\\export_coco-instance_charlie4611-_solar_panels_v0.5.4.json. Images and labels in segments\\charlie4611-_solar_panels\\v0.5.4\n"
     ]
    },
    {
     "data": {
      "text/plain": "('.\\\\export_coco-instance_charlie4611-_solar_panels_v0.5.4.json',\n 'segments\\\\charlie4611-_solar_panels\\\\v0.5.4')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = SegmentsDataset(\"C:/Users/Thomas/PycharmProjects/pythonProject/test.json\", labelset='ground-truth', filter_by=['labeled'])\n",
    "export_dataset(dataset_test, export_format='coco-instance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Some changes<h4>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "for details see cleanup-function above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "directory = \"C:/Users/Thomas/PycharmProjects/pythonProject/\" # do change\n",
    "cleanup(directory, \"export_coco-instance_train.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "directory = \"C:/Users/Thomas/PycharmProjects/pythonProject/\" # do change\n",
    "cleanup(directory, \"export_coco-instance_val.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "directory = \"C:/Users/Thomas/PycharmProjects/pythonProject/\" # do change\n",
    "cleanup(directory, \"export_coco-instance_test.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}